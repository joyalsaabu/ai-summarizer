{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db8f3f85-3696-4fa2-b381-4b978fc26231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the neccessary packages\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import gradio as gr\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "250ef2e5-4cf4-4634-9bf6-df6a4464ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppress known warning related to LangChain version compatibility\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"Convert_system_message_to_human will be deprecated!\",\n",
    "    module=\"langchain_google_genai.chat_models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1392471c-dcca-4d37-9443-cff6a976075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Gemini LLM with API key\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=\"PASTE YOUR API KEY HERE\", # (Note: Avoid hardcoding this in real apps)\n",
    "    convert_system_message_to_human=True\n",
    ")\n",
    "\n",
    "text_splitter = CharacterTextSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1c86015-94a1-4c68-8896-7209fecd5910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarization logic function\n",
    "def summarize_input(file, direct_text, custom_prompt=\"\"):\n",
    "    docs = []\n",
    "    # Case 1: File uploaded\n",
    "    if file is not None:\n",
    "        file_path = file.name\n",
    "        if file_path.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            docs = loader.load_and_split()\n",
    "        elif file_path.endswith(\".txt\"):\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "            docs = text_splitter.split_documents([Document(page_content=text)])\n",
    "    # Case 2: Direct text input instead of file\n",
    "    elif direct_text.strip() != \"\":\n",
    "        docs = text_splitter.split_documents([Document(page_content=direct_text)])\n",
    "\n",
    "    # If no valid input\n",
    "    if not docs:\n",
    "        return \"No input provided.\", \"\"\n",
    "\n",
    "    # Default prompt for summarization\n",
    "    default_prompt_template = \"\"\"\n",
    "    You are an expert summarizer.\n",
    "    Summarize the following document clearly and concisely using bullet points or short paragraphs. Avoid vague language.\n",
    "    {text}\n",
    "    SUMMARY:\n",
    "    \"\"\"\n",
    "     # Wrap default prompt in LangChain's PromptTemplate\n",
    "    DEFAULT_PROMPT = PromptTemplate(template=default_prompt_template, input_variables=[\"text\"])\n",
    "     # Build summarization chain using MapReduce approach\n",
    "    chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=DEFAULT_PROMPT, combine_prompt=DEFAULT_PROMPT)\n",
    "    # Run chain with document chunks and extract output\n",
    "    summary = chain.invoke({\"input_documents\": docs})[\"output_text\"]\n",
    "\n",
    "    # Optional: If user gives custom prompt\n",
    "    custom_summary = \"\"\n",
    "    if custom_prompt.strip() != \"\":\n",
    "        prompt_template = custom_prompt + \"\"\"\n",
    "        {text}\n",
    "        SUMMARY:\"\"\"\n",
    "        PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "        chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=PROMPT, combine_prompt=PROMPT)\n",
    "        custom_summary = chain.invoke({\"input_documents\": docs})[\"output_text\"]\n",
    "\n",
    "    return summary, custom_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8935892-fe00-499b-99ee-7314e1b49359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7874\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the Gradio interface\n",
    "def main():\n",
    "    file_input = gr.File(file_types=[\".pdf\", \".txt\"], label=\"Upload PDF or TXT File\")\n",
    "    direct_text_input = gr.Textbox(label=\"Or enter text directly\", lines=10, placeholder=\"Paste your text here...\")\n",
    "    input_custom_prompt = gr.Textbox(label=\"Enter your custom prompt (optional)\")\n",
    "    output_summary = gr.Textbox(label=\"Summary\", lines=10)\n",
    "    output_custom_summary = gr.Textbox(label=\"Custom Summary\", lines=10)\n",
    "\n",
    "    # Create the Gradio interface\n",
    "    iface = gr.Interface(\n",
    "        fn=summarize_input,\n",
    "        inputs=[file_input, direct_text_input, input_custom_prompt],\n",
    "        outputs=[output_summary, output_custom_summary],\n",
    "        title=\"Text Summarizer\",\n",
    "        description=\"Upload a PDF or TXT file, or paste text directly to get a summary.\",\n",
    "    )\n",
    "\n",
    "    iface.launch() # Run the web app\n",
    "\n",
    "# entry point for script\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf136c9-2bfe-4686-a7ae-57ed3d3d6660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
